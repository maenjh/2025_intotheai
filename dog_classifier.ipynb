{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cca76aa",
   "metadata": {},
   "source": [
    "# Dog vs AI‑Generated Dog Image Classifier\n",
    "본 노트북은 `dog_classifier.py` 스크립트를 Jupyter Notebook 형식으로 변환한 것입니다. AI로 생성된 강아지 이미지와 실제 강아지 이미지를 분류하는 ResNet‑18 기반 모델의 데이터 전처리, 학습, 평가 과정을 단계별로 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_gpu_info():\n",
    "    \"\"\"GPU 정보 출력\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"Free GPU Memory: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "DATA_ROOT = os.path.join(os.path.expanduser(\"~\"), \"workspace\", \"projects\", \"intotheai\", \"data\", \"Dogs Vs AiDogs\", \"Dogs Vs AiDogs\")\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\", \"images\")\n",
    "VALID_DIR = os.path.join(DATA_ROOT, \"valid\", \"images\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"test\", \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 변환 정의\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 클래스 정의\n",
    "class DogDataset(Dataset):\n",
    "    def __init__(self, dir_path, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(dir_path) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.dir_path, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = 0 if img_name.startswith('ai_') else 1\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26641494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성 함수\n",
    "def get_dataloaders(batch_size=32):\n",
    "    train_dataset = DogDataset(TRAIN_DIR, transform=train_transform)\n",
    "    valid_dataset = DogDataset(VALID_DIR, transform=test_transform)\n",
    "    test_dataset = DogDataset(TEST_DIR, transform=test_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의 (ResNet‑18 기반)\n",
    "def get_model():\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8464dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    best_val_acc = 0.0\n",
    "    model_save_path = 'best_dog_classifier.pth'\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_losses.append(running_loss / len(train_loader.dataset))\n",
    "        train_accs.append(100 * correct / total)\n",
    "        model.eval(); running_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(valid_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Valid]'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_losses.append(running_loss / len(valid_loader.dataset))\n",
    "        val_accs.append(100 * correct / total)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.2f}%, Valid Loss: {val_losses[-1]:.4f}, Valid Acc: {val_accs[-1]:.2f}%')\n",
    "        if val_accs[-1] > best_val_acc:\n",
    "            best_val_acc = val_accs[-1]\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f'Model saved with validation accuracy: {best_val_acc:.2f}%')\n",
    "    return model, {'train_loss': train_losses, 'val_loss': val_losses, 'train_acc': train_accs, 'val_acc': val_accs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 및 시각화 함수들\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device); model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Evaluating'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    accuracy = sum(1 for i, j in zip(y_true, y_pred) if i == j) / len(y_true)\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, target_names=['AI Generated', 'Real']))\n",
    "    return accuracy, cm\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over epochs'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs'); plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def predict_and_visualize(model, test_loader, num_samples=10):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device); model.eval()\n",
    "    inv_normalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], std=[1/0.229, 1/0.224, 1/0.225])\n",
    "    images, labels, preds = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_imgs, batch_labels in test_loader:\n",
    "            batch_imgs, batch_labels = batch_imgs.to(device), batch_labels.to(device)\n",
    "            outputs = model(batch_imgs)\n",
    "            _, batch_preds = torch.max(outputs, 1)\n",
    "            for i in range(batch_imgs.size(0)):\n",
    "                images.append(inv_normalize(batch_imgs[i]).cpu())\n",
    "                labels.append(batch_labels[i].item())\n",
    "                preds.append(batch_preds[i].item())\n",
    "                if len(images) >= num_samples:\n",
    "                    break\n",
    "            if len(images) >= num_samples:\n",
    "                break\n",
    "    class_names = ['AI Generated', 'Real']\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15,6)); axes = axes.flatten()\n",
    "    for i, (img, label, pred) in enumerate(zip(images, labels, preds)):\n",
    "        img = img.permute(1,2,0).numpy(); img = np.clip(img, 0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        color = 'green' if label == pred else 'red'\n",
    "        axes[i].set_title(f'True: {class_names[label]}\\nPred: {class_names[pred]}', color=color)\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfecac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스별 이미지 개수 계산 함수\n",
    "def calculate_class_distribution(dataset):\n",
    "    labels = [0 if img.startswith('ai_') else 1 for img in dataset.images]\n",
    "    return labels.count(0), labels.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 실행 예시 =====================\n",
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 512\n",
    "    NUM_EPOCHS = 10\n",
    "    print_gpu_info()\n",
    "    train_loader, valid_loader, test_loader = get_dataloaders(batch_size=BATCH_SIZE)\n",
    "    print('Dataset Statistics:')\n",
    "    print(f\"Training - AI Generated: {calculate_class_distribution(train_loader.dataset)[0]}, Real: {calculate_class_distribution(train_loader.dataset)[1]}\")\n",
    "    model = get_model()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    trained_model, history = train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)\n",
    "    plot_training_history(history)\n",
    "    model.load_state_dict(torch.load('best_dog_classifier.pth'))\n",
    "    evaluate_model(model, test_loader)\n",
    "    predict_and_visualize(model, test_loader, num_samples=10)\n",
    "    print('Training and evaluation completed!')\n",
    "    torch.backends.cudnn.benchmark = True  # GPU 성능 최적화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "today",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
